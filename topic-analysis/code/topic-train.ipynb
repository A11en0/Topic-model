{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conditional-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "# Reading data back\n",
    "def openJsonFile(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "    # resp = json.loads(u.read().decode('utf-8'))\n",
    "    \n",
    "def FindAllFile(base):\n",
    "    for root, ds, fs in os.walk(base):\n",
    "        for f in fs:\n",
    "            yield f\n",
    "            \n",
    "# 创建停用词列表\n",
    "def stopwordslist():\n",
    "    stopwords = [line.strip() for line in open('/home/featurize/data/stopwords.txt', 'r', encoding='UTF-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "# 定义停词函数 对句子进行中文分词\n",
    "def seg_depart(sentence):\n",
    "    # 对文档中的每一行进行中文分词\n",
    "    sentence_depart = jieba.cut(sentence.strip())\n",
    "    # 创建一个停用词列表\n",
    "    stopwords = stopwordslist()\n",
    "    # 去停用词\n",
    "    output = filter(lambda x: x not in stopwords and x != '\\xa0' and not x.isnumeric() and len(x.strip())>1, sentence_depart)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constant-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'古代': [], '当代': [], '现代': [], '近代': []}\n"
     ]
    }
   ],
   "source": [
    "database = \"/home/featurize/data/resultJson/\"\n",
    "\n",
    "label_set = ['古代', '当代', '现代', '近代']\n",
    "sample_set = dict(zip(label_set, [[], [], [], []]))\n",
    "print(sample_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neutral-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in FindAllFile(database):\n",
    "    label = filename.split(\"-\")[1].split(\"(\")[1][:-1]\n",
    "    content = openJsonFile(database + filename)[\"人物简介\"][\"text\"]\n",
    "    sample_set[label].append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extended-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词测试\n",
    "# seg = list(seg_depart(gudai[1]))\n",
    "# # seg = \" \".join(seg)\n",
    "# print(seg)\n",
    "# gudai[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "junior-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seg_corpus(contents, save_path):\n",
    "#     # 分词\n",
    "#     path = save_path + \"seg.csv\"\n",
    "#     if os.path.exists(path):\n",
    "#         df = pd.read_csv(path, header=None, delimiter=\"\\t\", names=[\"raw\", \"seg\"])\n",
    "#     else:\n",
    "#         result_seg = []\n",
    "#         for content in contents:\n",
    "#             seg = list(seg_depart(content))\n",
    "#             seg = \" \".join(seg)\n",
    "#             if len(seg) > 0:\n",
    "#                 result_seg.append([content, seg])\n",
    "\n",
    "#         df = pd.DataFrame(result_seg, columns=['raw', 'seg'])\n",
    "# #        df.to_csv(\"/home/featurize/data/seg_text.csv\", index=False, header=None, sep=\"\\t\")\n",
    "#         df.to_csv(path, index=False, header=None, sep=\"\\t\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "every-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_corpus(contents, save_path):\n",
    "    # 分词\n",
    "    result_seg = []\n",
    "    for content in contents:\n",
    "        seg = list(seg_depart(content))\n",
    "        seg = \" \".join(seg)\n",
    "        if len(seg) > 0:\n",
    "            result_seg.append([content, seg])\n",
    "\n",
    "    df = pd.DataFrame(result_seg, columns=['raw', 'seg'])\n",
    "    # df.to_csv(path, index=False, header=None, sep=\"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "finnish-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_dict(df):\n",
    "    docs = df.seg.apply(lambda x: x.split())\n",
    "    \n",
    "    # Remove rare and common tokens.\n",
    "    from gensim.corpora import Dictionary\n",
    "    \n",
    "    # Create a dictionary representation of the documents.\n",
    "    dictionary = Dictionary(docs)\n",
    "    \n",
    "    # Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "    dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "                                                        \n",
    "    corpus = [dictionary.doc2bow(list(doc)) for doc in docs]\n",
    "    return dictionary, docs, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greatest-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dictionary, docs, corpus):\n",
    "    # Train LDA model.\n",
    "    # Set training parameters.\n",
    "    # num_topics = 10\n",
    "    chunksize = 2000\n",
    "    passes = 20\n",
    "    iterations = 400\n",
    "    eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "    s = 2\n",
    "    e = 40\n",
    "    # Make a index to word dictionary.\n",
    "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "    id2word = dictionary.id2token\n",
    "    \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(s, e, 2):\n",
    "        lda = LdaMulticore(\n",
    "            corpus,\n",
    "            id2word=id2word,\n",
    "            num_topics=num_topics,\n",
    "            iterations=iterations,\n",
    "            eval_every=eval_every\n",
    "        )\n",
    "        model_list.append(lda)\n",
    "        coherencemodel = CoherenceModel(model=lda, texts=docs,\n",
    "                                        dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(round(coherencemodel.get_coherence(), 3))\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excited-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(dictionary, docs, corpus, save_path):\n",
    "    from pprint import pprint\n",
    "    print('Number of unique tokens: %d' % len(dictionary))\n",
    "    print('Number of documents: %d' % len(corpus))\n",
    "    model_list, coherence_values = train_model(dictionary, docs, corpus)\n",
    "    best_id = np.argmax(np.array(coherence_values))\n",
    "    model = model_list[best_id]\n",
    "    pprint(model.print_topics(num_words=20))\n",
    "    # 保存最佳模型\n",
    "    # model.save(\"/home/featurize/data/topics/best_model.lda\")\n",
    "    print(save_path)\n",
    "    model.save(save_path + \"best_model.lda\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "willing-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(corpus, model, dictionary, save_path):\n",
    "    '''\n",
    "    可视化函数，输入语料、模型和字典文件，输出html文件\n",
    "    corpus: 输入语料\n",
    "    model: 模型\n",
    "    dictionary: 字典\n",
    "    save_path: html保存路径\n",
    "    '''\n",
    "    import pyLDAvis.gensim_models as gensimvis\n",
    "    import pyLDAvis\n",
    "    vis = gensimvis.prepare(model, corpus, dictionary)\n",
    "#    pyLDAvis.show(vis)\n",
    "    pyLDAvis.save_html(vis, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "referenced-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "\n",
    "def main(save_path, df):\n",
    "    dictionary, docs, corpus = get_corpus_dict(df)\n",
    "    # 保存corpus\n",
    "    MmCorpus.serialize(save_path + 'data_corpus.mm', corpus)\n",
    "    # 保存dict\n",
    "    dictionary.save(save_path + 'doc2bow.dict')\n",
    "    model = get_best_model(dictionary, docs, corpus, save_path)\n",
    "    visualization(corpus, model, dictionary, save_path+ \"vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tropical-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "gudai = sample_set[\"古代\"]\n",
    "dangdai = sample_set[\"当代\"]\n",
    "xiandai = sample_set[\"现代\"]\n",
    "jindai = sample_set[\"近代\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "australian-locking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.858 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 649\n",
      "Number of documents: 1326\n",
      "[(1,\n",
      "  '0.037*\"孙中山\" + 0.019*\"中华民国\" + 0.018*\"伟大\" + 0.016*\"民国\" + 0.014*\"中国\" + '\n",
      "  '0.014*\"出版\" + 0.012*\"北京\" + 0.012*\"逝世\" + 0.012*\"委员\" + 0.011*\"香港\" + 0.011*\"主任\" '\n",
      "  '+ 0.010*\"总统\" + 0.010*\"袁世凯\" + 0.009*\"天津\" + 0.009*\"生于\" + 0.008*\"创立\" + '\n",
      "  '0.008*\"原名\" + 0.008*\"光绪\" + 0.007*\"国民党\" + 0.007*\"成立\"'),\n",
      " (10,\n",
      "  '0.031*\"上海\" + 0.025*\"光绪\" + 0.022*\"光绪帝\" + 0.016*\"中国\" + 0.015*\"日本\" + '\n",
      "  '0.014*\"生于\" + 0.013*\"成为\" + 0.012*\"北京\" + 0.012*\"清朝\" + 0.012*\"皇帝\" + '\n",
      "  '0.009*\"国民党\" + 0.009*\"反对\" + 0.008*\"势力\" + 0.008*\"历史\" + 0.008*\"亲王\" + '\n",
      "  '0.007*\"享年\" + 0.007*\"袁世凯\" + 0.007*\"同志\" + 0.007*\"爱新觉罗\" + 0.007*\"组织\"'),\n",
      " (13,\n",
      "  '0.036*\"中国\" + 0.020*\"日本\" + 0.019*\"教授\" + 0.018*\"研究\" + 0.018*\"文化\" + 0.017*\"鲁迅\" '\n",
      "  '+ 0.014*\"著名\" + 0.012*\"发展\" + 0.012*\"哲学\" + 0.012*\"思想\" + 0.012*\"浙江\" + '\n",
      "  '0.011*\"生于\" + 0.010*\"先生\" + 0.010*\"笔名\" + 0.010*\"早年\" + 0.009*\"现代\" + 0.009*\"领域\" '\n",
      "  '+ 0.008*\"近代\" + 0.008*\"影响\" + 0.008*\"毕业\"'),\n",
      " (9,\n",
      "  '0.029*\"中国\" + 0.018*\"民国\" + 0.016*\"上海\" + 0.014*\"参加\" + 0.013*\"日本\" + 0.010*\"生于\" '\n",
      "  '+ 0.010*\"委员\" + 0.010*\"光绪\" + 0.010*\"主席\" + 0.009*\"鲁迅\" + 0.008*\"天津\" + '\n",
      "  '0.008*\"中国共产党\" + 0.008*\"孙中山\" + 0.008*\"国民党\" + 0.008*\"委员会\" + 0.007*\"病逝\" + '\n",
      "  '0.007*\"著名\" + 0.007*\"加入\" + 0.007*\"中央\" + 0.007*\"历任\"'),\n",
      " (7,\n",
      "  '0.025*\"中国\" + 0.023*\"上海\" + 0.016*\"日本\" + 0.016*\"大学\" + 0.015*\"毕业\" + 0.013*\"年任\" '\n",
      "  '+ 0.010*\"后任\" + 0.010*\"曾任\" + 0.010*\"广州\" + 0.009*\"学校\" + 0.009*\"中共\" + '\n",
      "  '0.009*\"原名\" + 0.009*\"加入\" + 0.009*\"病逝\" + 0.008*\"部长\" + 0.008*\"生于\" + 0.008*\"院长\" '\n",
      "  '+ 0.008*\"近代\" + 0.008*\"国民政府\" + 0.008*\"艺术\"'),\n",
      " (18,\n",
      "  '0.023*\"司令员\" + 0.019*\"苏联\" + 0.018*\"参加\" + 0.018*\"参谋长\" + 0.015*\"一级\" + '\n",
      "  '0.013*\"军区\" + 0.012*\"勋章\" + 0.011*\"中国\" + 0.011*\"军事\" + 0.011*\"中国人民解放军\" + '\n",
      "  '0.010*\"战役\" + 0.010*\"上将\" + 0.010*\"陆军\" + 0.010*\"历任\" + 0.010*\"享年\" + '\n",
      "  '0.010*\"中国共产党\" + 0.010*\"授予\" + 0.009*\"加入\" + 0.009*\"湖南\" + 0.008*\"中华人民共和国\"'),\n",
      " (11,\n",
      "  '0.047*\"中国\" + 0.013*\"著名\" + 0.011*\"原名\" + 0.010*\"毛泽东\" + 0.010*\"现代\" + '\n",
      "  '0.008*\"近代\" + 0.008*\"中国共产党\" + 0.008*\"政治\" + 0.008*\"研究\" + 0.007*\"称为\" + '\n",
      "  '0.007*\"人物\" + 0.007*\"浙江\" + 0.007*\"主要\" + 0.007*\"逝世\" + 0.007*\"领导人\" + '\n",
      "  '0.006*\"北京\" + 0.006*\"先后\" + 0.006*\"担任\" + 0.006*\"生于\" + 0.006*\"抗日\"'),\n",
      " (20,\n",
      "  '0.034*\"中国\" + 0.020*\"担任\" + 0.016*\"学者\" + 0.014*\"美国\" + 0.014*\"主席\" + 0.013*\"原名\" '\n",
      "  '+ 0.013*\"苏联\" + 0.012*\"领导人\" + 0.012*\"著名\" + 0.011*\"委员\" + 0.011*\"中国共产党\" + '\n",
      "  '0.010*\"杰出\" + 0.010*\"时期\" + 0.009*\"革命\" + 0.009*\"政治\" + 0.009*\"司令员\" + '\n",
      "  '0.008*\"影响\" + 0.008*\"国家\" + 0.008*\"生于\" + 0.008*\"革命家\"'),\n",
      " (19,\n",
      "  '0.116*\"电影\" + 0.060*\"剧情\" + 0.039*\"获得\" + 0.026*\"上映\" + 0.022*\"中国\" + 0.018*\"生于\" '\n",
      "  '+ 0.016*\"战争\" + 0.015*\"主演\" + 0.012*\"影片\" + 0.012*\"演员\" + 0.012*\"勋章\" + '\n",
      "  '0.012*\"一级\" + 0.011*\"局长\" + 0.011*\"国际\" + 0.011*\"原名\" + 0.010*\"家庭\" + 0.010*\"个人\" '\n",
      "  '+ 0.010*\"内地\" + 0.010*\"首部\" + 0.008*\"独立\"'),\n",
      " (17,\n",
      "  '0.021*\"主席\" + 0.021*\"中国\" + 0.016*\"中共\" + 0.016*\"中国共产党\" + 0.016*\"委员\" + '\n",
      "  '0.013*\"委员会\" + 0.013*\"中共中央\" + 0.012*\"担任\" + 0.011*\"北京\" + 0.011*\"书记\" + '\n",
      "  '0.010*\"领导人\" + 0.010*\"无产阶级\" + 0.009*\"逝世\" + 0.009*\"革命家\" + 0.009*\"生于\" + '\n",
      "  '0.009*\"院长\" + 0.008*\"参加\" + 0.008*\"中华人民共和国\" + 0.008*\"加入\" + 0.008*\"曾任\"'),\n",
      " (14,\n",
      "  '0.022*\"参加\" + 0.013*\"京剧\" + 0.013*\"委员\" + 0.013*\"北京\" + 0.013*\"军长\" + 0.012*\"抗战\" '\n",
      "  '+ 0.012*\"中国\" + 0.010*\"主席\" + 0.010*\"陆军\" + 0.010*\"著名\" + 0.009*\"上海\" + '\n",
      "  '0.009*\"日军\" + 0.009*\"委员会\" + 0.009*\"逝世\" + 0.009*\"曾任\" + 0.008*\"将领\" + '\n",
      "  '0.008*\"率部\" + 0.008*\"享年\" + 0.008*\"国民革命军\" + 0.008*\"抗日\"'),\n",
      " (25,\n",
      "  '0.058*\"中国\" + 0.016*\"委员\" + 0.012*\"北京\" + 0.010*\"原名\" + 0.010*\"生于\" + 0.009*\"历任\" '\n",
      "  '+ 0.009*\"上海\" + 0.009*\"著名\" + 0.009*\"现代\" + 0.009*\"代表\" + 0.008*\"院长\" + '\n",
      "  '0.008*\"常委\" + 0.008*\"主席\" + 0.008*\"逝世\" + 0.008*\"教育家\" + 0.008*\"教授\" + '\n",
      "  '0.008*\"全国政协\" + 0.008*\"委员会\" + 0.007*\"政治\" + 0.007*\"蒋介石\"'),\n",
      " (5,\n",
      "  '0.047*\"中国\" + 0.019*\"梁启超\" + 0.016*\"北京\" + 0.015*\"光绪\" + 0.014*\"出版\" + '\n",
      "  '0.013*\"委员\" + 0.013*\"现代\" + 0.010*\"笔名\" + 0.010*\"原名\" + 0.009*\"生于\" + 0.008*\"代表\" '\n",
      "  '+ 0.008*\"享年\" + 0.008*\"长篇小说\" + 0.008*\"日本\" + 0.007*\"创作\" + 0.007*\"曾任\" + '\n",
      "  '0.007*\"主席\" + 0.007*\"先生\" + 0.007*\"上海\" + 0.007*\"逝世\"'),\n",
      " (3,\n",
      "  '0.035*\"中国\" + 0.031*\"美国\" + 0.018*\"总统\" + 0.017*\"参加\" + 0.012*\"教授\" + 0.012*\"生于\" '\n",
      "  '+ 0.011*\"香港\" + 0.010*\"逝世\" + 0.010*\"担任\" + 0.010*\"享年\" + 0.009*\"台湾\" + '\n",
      "  '0.009*\"北京\" + 0.008*\"广东\" + 0.008*\"中共\" + 0.008*\"教育\" + 0.008*\"成立\" + 0.007*\"成为\" '\n",
      "  '+ 0.007*\"期间\" + 0.007*\"历任\" + 0.007*\"毕业\"'),\n",
      " (22,\n",
      "  '0.024*\"中国共产党\" + 0.023*\"司令员\" + 0.019*\"革命\" + 0.017*\"苏联\" + 0.015*\"参加\" + '\n",
      "  '0.015*\"中国\" + 0.015*\"领导人\" + 0.014*\"无产阶级\" + 0.013*\"原名\" + 0.012*\"革命家\" + '\n",
      "  '0.012*\"加入\" + 0.011*\"历史\" + 0.011*\"同志\" + 0.011*\"生于\" + 0.010*\"工作\" + 0.009*\"重要\" '\n",
      "  '+ 0.008*\"主席\" + 0.008*\"军区\" + 0.008*\"著名\" + 0.007*\"中国人民解放军\"'),\n",
      " (26,\n",
      "  '0.024*\"粤剧\" + 0.021*\"著名\" + 0.020*\"原名\" + 0.019*\"香港\" + 0.018*\"中国\" + 0.017*\"广东\" '\n",
      "  '+ 0.017*\"京剧\" + 0.016*\"广州\" + 0.016*\"电影\" + 0.012*\"生于\" + 0.011*\"学习\" + '\n",
      "  '0.010*\"北京\" + 0.010*\"先后\" + 0.009*\"演员\" + 0.008*\"主张\" + 0.008*\"当时\" + 0.008*\"民国\" '\n",
      "  '+ 0.008*\"担任\" + 0.008*\"广东省\" + 0.008*\"人物\"'),\n",
      " (23,\n",
      "  '0.038*\"中国\" + 0.026*\"电影\" + 0.018*\"上海\" + 0.017*\"名誉\" + 0.014*\"主席\" + 0.013*\"生于\" '\n",
      "  '+ 0.012*\"毕业\" + 0.011*\"大学\" + 0.011*\"剧情\" + 0.011*\"北京\" + 0.010*\"著名\" + '\n",
      "  '0.009*\"校长\" + 0.009*\"曾任\" + 0.009*\"公司\" + 0.009*\"江苏\" + 0.009*\"享年\" + 0.008*\"回国\" '\n",
      "  '+ 0.008*\"美国\" + 0.007*\"获得\" + 0.007*\"研究\"'),\n",
      " (27,\n",
      "  '0.033*\"中国\" + 0.031*\"电影\" + 0.015*\"委员\" + 0.015*\"中国共产党\" + 0.013*\"生于\" + '\n",
      "  '0.012*\"原名\" + 0.011*\"中共\" + 0.011*\"部长\" + 0.010*\"加入\" + 0.009*\"毛泽东\" + '\n",
      "  '0.009*\"重要\" + 0.009*\"领导人\" + 0.008*\"主演\" + 0.008*\"参加\" + 0.007*\"逝世\" + '\n",
      "  '0.007*\"享年\" + 0.007*\"文学\" + 0.007*\"出版\" + 0.007*\"主席\" + 0.007*\"中央\"'),\n",
      " (15,\n",
      "  '0.034*\"中国\" + 0.019*\"生于\" + 0.015*\"加入\" + 0.015*\"中国共产党\" + 0.015*\"参加\" + '\n",
      "  '0.015*\"京剧\" + 0.013*\"抗战\" + 0.013*\"军事\" + 0.013*\"毕业\" + 0.012*\"革命\" + 0.011*\"原名\" '\n",
      "  '+ 0.011*\"日本\" + 0.010*\"著名\" + 0.009*\"委员\" + 0.009*\"曾任\" + 0.008*\"作品\" + '\n",
      "  '0.008*\"教育家\" + 0.008*\"清末\" + 0.008*\"成为\" + 0.007*\"期间\"'),\n",
      " (4,\n",
      "  '0.029*\"北京\" + 0.020*\"中国\" + 0.017*\"参加\" + 0.016*\"电影\" + 0.016*\"中国共产党\" + '\n",
      "  '0.014*\"逝世\" + 0.013*\"生于\" + 0.013*\"主席\" + 0.012*\"委员\" + 0.011*\"享年\" + 0.011*\"加入\" '\n",
      "  '+ 0.011*\"同治\" + 0.011*\"原名\" + 0.010*\"部长\" + 0.008*\"日本\" + 0.008*\"民国\" + '\n",
      "  '0.008*\"著名\" + 0.008*\"工作\" + 0.007*\"委员会\" + 0.007*\"夫人\"')]\n",
      "/home/featurize/data/topics/jindai/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/featurize/data/topics/jindai/\"\n",
    "df_jindai = seg_corpus(jindai, save_path)\n",
    "main(save_path, df_jindai)\n",
    "# df_jindai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "preceding-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 393\n",
      "Number of documents: 1023\n",
      "[(0,\n",
      "  '0.044*\"演员\" + 0.026*\"电视剧\" + 0.024*\"京剧\" + 0.021*\"香港\" + 0.019*\"相声\" + '\n",
      "  '0.019*\"中国\" + 0.016*\"获得\" + 0.015*\"先生\" + 0.015*\"李小龙\" + 0.014*\"出演\" + '\n",
      "  '0.012*\"北京\" + 0.012*\"著名\" + 0.011*\"艺术\" + 0.011*\"父亲\" + 0.010*\"话剧\" + 0.010*\"电影\" '\n",
      "  '+ 0.010*\"参加\" + 0.010*\"戏剧\" + 0.010*\"美国\" + 0.010*\"出生\"'),\n",
      " (1,\n",
      "  '0.022*\"台湾\" + 0.020*\"导演\" + 0.020*\"北京\" + 0.018*\"原名\" + 0.017*\"著名\" + 0.016*\"毕业\" '\n",
      "  '+ 0.016*\"演员\" + 0.015*\"电影\" + 0.014*\"执导\" + 0.014*\"中国\" + 0.012*\"浙江省\" + '\n",
      "  '0.012*\"主演\" + 0.012*\"浙江\" + 0.012*\"参加\" + 0.011*\"工作\" + 0.011*\"电视剧\" + '\n",
      "  '0.011*\"享年\" + 0.010*\"全国\" + 0.010*\"香港\" + 0.010*\"美国\"'),\n",
      " (2,\n",
      "  '0.053*\"电影\" + 0.041*\"最佳\" + 0.034*\"获得\" + 0.024*\"演员\" + 0.020*\"主演\" + 0.018*\"香港\" '\n",
      "  '+ 0.018*\"中国\" + 0.015*\"导演\" + 0.014*\"出演\" + 0.014*\"台湾\" + 0.014*\"电视剧\" + '\n",
      "  '0.012*\"执导\" + 0.011*\"参演\" + 0.010*\"电影节\" + 0.010*\"享年\" + 0.009*\"日出\" + '\n",
      "  '0.009*\"编剧\" + 0.009*\"金马奖\" + 0.009*\"喜剧片\" + 0.009*\"提名\"'),\n",
      " (3,\n",
      "  '0.045*\"电影\" + 0.030*\"中国\" + 0.026*\"香港\" + 0.025*\"获得\" + 0.019*\"执导\" + 0.017*\"台湾\" '\n",
      "  '+ 0.015*\"最佳\" + 0.014*\"演员\" + 0.013*\"上海\" + 0.012*\"主席\" + 0.010*\"出演\" + '\n",
      "  '0.010*\"电视剧\" + 0.010*\"著名\" + 0.010*\"毕业\" + 0.010*\"研究\" + 0.010*\"日出\" + '\n",
      "  '0.009*\"拍摄\" + 0.008*\"担任\" + 0.008*\"上映\" + 0.008*\"成为\"'),\n",
      " (4,\n",
      "  '0.091*\"电影\" + 0.038*\"主演\" + 0.032*\"中国\" + 0.029*\"获得\" + 0.018*\"剧情\" + 0.018*\"饰演\" '\n",
      "  '+ 0.016*\"演员\" + 0.016*\"出演\" + 0.013*\"最佳\" + 0.013*\"导演\" + 0.013*\"香港\" + '\n",
      "  '0.012*\"电视剧\" + 0.012*\"执导\" + 0.010*\"上映\" + 0.010*\"毕业\" + 0.009*\"担任\" + '\n",
      "  '0.009*\"参演\" + 0.008*\"编剧\" + 0.008*\"北京\" + 0.007*\"成就奖\"'),\n",
      " (5,\n",
      "  '0.062*\"电影\" + 0.040*\"获得\" + 0.029*\"执导\" + 0.029*\"中国\" + 0.027*\"最佳\" + 0.022*\"美国\" '\n",
      "  '+ 0.020*\"导演\" + 0.013*\"国际\" + 0.013*\"电影节\" + 0.013*\"香港\" + 0.012*\"担任\" + '\n",
      "  '0.012*\"演员\" + 0.011*\"主演\" + 0.011*\"毕业\" + 0.011*\"参演\" + 0.010*\"出演\" + '\n",
      "  '0.010*\"电视剧\" + 0.009*\"上海\" + 0.008*\"该片\" + 0.008*\"享年\"'),\n",
      " (6,\n",
      "  '0.056*\"中国\" + 0.027*\"电影\" + 0.019*\"执导\" + 0.019*\"电视剧\" + 0.019*\"饰演\" + '\n",
      "  '0.017*\"参演\" + 0.017*\"主演\" + 0.016*\"演员\" + 0.015*\"出演\" + 0.012*\"研究\" + 0.011*\"担任\" '\n",
      "  '+ 0.011*\"导演\" + 0.011*\"院士\" + 0.010*\"教授\" + 0.010*\"毕业\" + 0.009*\"优秀\" + '\n",
      "  '0.008*\"香港\" + 0.008*\"日出\" + 0.008*\"获得\" + 0.008*\"话剧\"'),\n",
      " (7,\n",
      "  '0.050*\"相声\" + 0.040*\"演员\" + 0.029*\"中国\" + 0.026*\"北京\" + 0.019*\"香港\" + '\n",
      "  '0.018*\"国家一级\" + 0.017*\"代表性\" + 0.014*\"上海\" + 0.014*\"国家级\" + 0.014*\"文化遗产\" + '\n",
      "  '0.014*\"物质\" + 0.014*\"传承\" + 0.014*\"项目\" + 0.013*\"理事\" + 0.012*\"出生\" + 0.010*\"著名\" '\n",
      "  '+ 0.010*\"艺术\" + 0.010*\"毕业\" + 0.010*\"汉族\" + 0.009*\"逝世\"')]\n",
      "/home/featurize/data/topics/xiandai/\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/featurize/data/topics/xiandai/\"\n",
    "df_xiandai = seg_corpus(xiandai, save_path)\n",
    "main(save_path, df_xiandai)\n",
    "# df_xiandai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stupid-consumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 2588\n",
      "Number of documents: 6730\n",
      "[(15,\n",
      "  '0.028*\"电视剧\" + 0.025*\"出演\" + 0.023*\"最佳\" + 0.015*\"执导\" + 0.015*\"饰演\" + '\n",
      "  '0.014*\"男演员\" + 0.011*\"毕业\" + 0.010*\"导演\" + 0.010*\"同年\" + 0.009*\"内地\" + '\n",
      "  '0.009*\"参演\" + 0.008*\"爱情\" + 0.008*\"演员\" + 0.008*\"担任\" + 0.007*\"古装\" + 0.007*\"香港\" '\n",
      "  '+ 0.007*\"电视\" + 0.007*\"首部\" + 0.007*\"提名\" + 0.006*\"电影节\"'),\n",
      " (9,\n",
      "  '0.032*\"参演\" + 0.028*\"出演\" + 0.024*\"电视剧\" + 0.019*\"饰演\" + 0.014*\"参加\" + '\n",
      "  '0.012*\"女演员\" + 0.011*\"最佳\" + 0.011*\"毕业\" + 0.011*\"古装\" + 0.010*\"内地\" + '\n",
      "  '0.010*\"同年\" + 0.008*\"香港\" + 0.008*\"演员\" + 0.007*\"影视\" + 0.006*\"时装\" + 0.006*\"年度\" '\n",
      "  '+ 0.005*\"北京\" + 0.005*\"湖南卫视\" + 0.005*\"TVB\" + 0.005*\"歌手\"'),\n",
      " (4,\n",
      "  '0.041*\"出演\" + 0.027*\"古装\" + 0.026*\"饰演\" + 0.015*\"爱情\" + 0.015*\"都市\" + '\n",
      "  '0.014*\"电视剧\" + 0.013*\"同年\" + 0.011*\"毕业\" + 0.011*\"播出\" + 0.011*\"情感\" + '\n",
      "  '0.010*\"励志\" + 0.009*\"内地\" + 0.009*\"正式\" + 0.009*\"个人\" + 0.008*\"男演员\" + '\n",
      "  '0.008*\"参加\" + 0.008*\"进入\" + 0.008*\"演艺圈\" + 0.008*\"演员\" + 0.007*\"参演\"'),\n",
      " (6,\n",
      "  '0.031*\"出演\" + 0.014*\"同年\" + 0.014*\"最佳\" + 0.012*\"香港\" + 0.011*\"发行\" + '\n",
      "  '0.011*\"电视剧\" + 0.010*\"参演\" + 0.010*\"爱情\" + 0.009*\"演员\" + 0.009*\"专辑\" + '\n",
      "  '0.009*\"个人\" + 0.009*\"女演员\" + 0.008*\"台湾\" + 0.008*\"古装\" + 0.008*\"都市\" + '\n",
      "  '0.007*\"内地\" + 0.007*\"饰演\" + 0.007*\"毕业\" + 0.007*\"参加\" + 0.006*\"首部\"'),\n",
      " (17,\n",
      "  '0.032*\"电视剧\" + 0.031*\"最佳\" + 0.024*\"出演\" + 0.020*\"电影节\" + 0.014*\"国际\" + '\n",
      "  '0.012*\"女演员\" + 0.012*\"执导\" + 0.012*\"导演\" + 0.011*\"担任\" + 0.011*\"毕业\" + '\n",
      "  '0.011*\"参演\" + 0.009*\"饰演\" + 0.009*\"同年\" + 0.009*\"内地\" + 0.008*\"男演员\" + '\n",
      "  '0.008*\"演员\" + 0.007*\"上海\" + 0.007*\"古装\" + 0.007*\"都市\" + 0.007*\"影视\"'),\n",
      " (7,\n",
      "  '0.031*\"参演\" + 0.027*\"饰演\" + 0.024*\"最佳\" + 0.023*\"电视剧\" + 0.016*\"女演员\" + '\n",
      "  '0.014*\"出演\" + 0.010*\"毕业\" + 0.010*\"古装\" + 0.009*\"主角奖\" + 0.009*\"内地\" + '\n",
      "  '0.008*\"同年\" + 0.008*\"参加\" + 0.007*\"电影节\" + 0.007*\"影视\" + 0.006*\"一角\" + '\n",
      "  '0.006*\"演员\" + 0.006*\"台湾\" + 0.006*\"传奇\" + 0.006*\"男演员\" + 0.005*\"导演\"'),\n",
      " (3,\n",
      "  '0.028*\"最佳\" + 0.018*\"电视剧\" + 0.015*\"饰演\" + 0.015*\"参演\" + 0.014*\"执导\" + '\n",
      "  '0.011*\"香港\" + 0.011*\"出演\" + 0.011*\"毕业\" + 0.009*\"女演员\" + 0.009*\"古装\" + '\n",
      "  '0.009*\"内地\" + 0.008*\"担任\" + 0.008*\"主角奖\" + 0.008*\"爱情\" + 0.008*\"同年\" + '\n",
      "  '0.008*\"演员\" + 0.008*\"电视\" + 0.007*\"影视\" + 0.007*\"上映\" + 0.006*\"男演员\"'),\n",
      " (14,\n",
      "  '0.023*\"出演\" + 0.019*\"电视剧\" + 0.016*\"主持\" + 0.015*\"香港\" + 0.014*\"参演\" + '\n",
      "  '0.013*\"饰演\" + 0.012*\"主持人\" + 0.010*\"毕业\" + 0.010*\"女演员\" + 0.009*\"节目\" + '\n",
      "  '0.008*\"内地\" + 0.008*\"担任\" + 0.007*\"古装\" + 0.006*\"最佳\" + 0.006*\"一角\" + 0.006*\"进入\" '\n",
      "  '+ 0.005*\"正式\" + 0.005*\"歌手\" + 0.005*\"首部\" + 0.005*\"演员\"'),\n",
      " (8,\n",
      "  '0.031*\"饰演\" + 0.020*\"出演\" + 0.018*\"最佳\" + 0.017*\"电视剧\" + 0.015*\"同年\" + '\n",
      "  '0.013*\"参演\" + 0.011*\"男演员\" + 0.009*\"演员\" + 0.009*\"爱情\" + 0.009*\"香港\" + '\n",
      "  '0.009*\"个人\" + 0.008*\"韩国\" + 0.008*\"男主角\" + 0.008*\"都市\" + 0.008*\"发行\" + '\n",
      "  '0.007*\"情感\" + 0.007*\"首部\" + 0.007*\"专辑\" + 0.007*\"正式\" + 0.007*\"执导\"'),\n",
      " (5,\n",
      "  '0.022*\"最佳\" + 0.015*\"出演\" + 0.015*\"上映\" + 0.014*\"电视剧\" + 0.013*\"个人\" + '\n",
      "  '0.011*\"参演\" + 0.011*\"女演员\" + 0.009*\"同年\" + 0.009*\"动作\" + 0.009*\"演员\" + '\n",
      "  '0.008*\"台湾\" + 0.007*\"冠军\" + 0.007*\"爱情\" + 0.007*\"担任\" + 0.007*\"饰演\" + 0.007*\"韩国\" '\n",
      "  '+ 0.006*\"毕业\" + 0.006*\"主持\" + 0.006*\"香港\" + 0.006*\"首部\"'),\n",
      " (13,\n",
      "  '0.023*\"主持人\" + 0.021*\"节目\" + 0.021*\"主持\" + 0.020*\"担任\" + 0.011*\"最佳\" + '\n",
      "  '0.011*\"同年\" + 0.010*\"毕业\" + 0.010*\"演员\" + 0.010*\"卫视\" + 0.010*\"参加\" + 0.009*\"音乐\" '\n",
      "  '+ 0.009*\"台湾\" + 0.007*\"综艺节目\" + 0.007*\"湖南卫视\" + 0.007*\"内地\" + 0.006*\"专辑\" + '\n",
      "  '0.006*\"个人\" + 0.006*\"香港\" + 0.006*\"爸爸\" + 0.006*\"歌曲\"'),\n",
      " (11,\n",
      "  '0.029*\"电视剧\" + 0.020*\"饰演\" + 0.019*\"最佳\" + 0.018*\"出演\" + 0.011*\"演员\" + '\n",
      "  '0.011*\"爱情\" + 0.009*\"同年\" + 0.009*\"香港\" + 0.008*\"女演员\" + 0.008*\"毕业\" + '\n",
      "  '0.008*\"古装\" + 0.008*\"参加\" + 0.008*\"执导\" + 0.007*\"电视\" + 0.007*\"提名\" + 0.007*\"个人\" '\n",
      "  '+ 0.007*\"一角\" + 0.006*\"大奖\" + 0.006*\"女主角\" + 0.006*\"参演\"'),\n",
      " (18,\n",
      "  '0.028*\"饰演\" + 0.026*\"出演\" + 0.022*\"电视剧\" + 0.017*\"个人\" + 0.013*\"情感\" + '\n",
      "  '0.013*\"爱情\" + 0.013*\"都市\" + 0.012*\"参演\" + 0.011*\"首部\" + 0.011*\"担任\" + 0.010*\"同年\" '\n",
      "  '+ 0.009*\"古装\" + 0.008*\"毕业\" + 0.008*\"最佳\" + 0.008*\"推出\" + 0.007*\"内地\" + '\n",
      "  '0.007*\"年代\" + 0.007*\"进入\" + 0.007*\"演员\" + 0.007*\"正式\"'),\n",
      " (20,\n",
      "  '0.020*\"参演\" + 0.018*\"最佳\" + 0.016*\"出演\" + 0.013*\"电视剧\" + 0.011*\"饰演\" + '\n",
      "  '0.011*\"播出\" + 0.009*\"美国\" + 0.009*\"上映\" + 0.008*\"正式\" + 0.008*\"爱情\" + 0.008*\"演员\" '\n",
      "  '+ 0.007*\"毕业\" + 0.007*\"男演员\" + 0.007*\"主持\" + 0.007*\"内地\" + 0.007*\"影视\" + '\n",
      "  '0.006*\"卫视\" + 0.006*\"同年\" + 0.006*\"女演员\" + 0.006*\"进入\"'),\n",
      " (1,\n",
      "  '0.018*\"推出\" + 0.018*\"最佳\" + 0.016*\"个人\" + 0.015*\"专辑\" + 0.014*\"同年\" + 0.013*\"音乐\" '\n",
      "  '+ 0.012*\"毕业\" + 0.011*\"演员\" + 0.010*\"电视剧\" + 0.009*\"香港\" + 0.008*\"台湾\" + '\n",
      "  '0.008*\"担任\" + 0.008*\"爱情\" + 0.008*\"组合\" + 0.007*\"内地\" + 0.007*\"参加\" + 0.007*\"节目\" '\n",
      "  '+ 0.007*\"年度\" + 0.007*\"参演\" + 0.006*\"首张\"'),\n",
      " (12,\n",
      "  '0.018*\"电视剧\" + 0.016*\"最佳\" + 0.015*\"女演员\" + 0.013*\"出演\" + 0.013*\"毕业\" + '\n",
      "  '0.012*\"同年\" + 0.009*\"演员\" + 0.008*\"香港\" + 0.008*\"北京\" + 0.008*\"个人\" + 0.007*\"正式\" '\n",
      "  '+ 0.007*\"爱情\" + 0.007*\"参演\" + 0.007*\"都市\" + 0.007*\"饰演\" + 0.006*\"大奖\" + '\n",
      "  '0.006*\"首部\" + 0.005*\"内地\" + 0.005*\"古装\" + 0.005*\"影视\"'),\n",
      " (21,\n",
      "  '0.020*\"出演\" + 0.017*\"电视剧\" + 0.016*\"同年\" + 0.016*\"参加\" + 0.013*\"都市\" + '\n",
      "  '0.013*\"情感\" + 0.010*\"内地\" + 0.010*\"最佳\" + 0.009*\"个人\" + 0.009*\"毕业\" + 0.009*\"专辑\" '\n",
      "  '+ 0.008*\"演员\" + 0.008*\"饰演\" + 0.008*\"爱情\" + 0.008*\"女演员\" + 0.007*\"参演\" + '\n",
      "  '0.007*\"发行\" + 0.007*\"歌手\" + 0.007*\"古装\" + 0.006*\"音乐\"'),\n",
      " (2,\n",
      "  '0.027*\"专辑\" + 0.020*\"个人\" + 0.018*\"最佳\" + 0.017*\"音乐\" + 0.017*\"同年\" + 0.015*\"发行\" '\n",
      "  '+ 0.015*\"参演\" + 0.015*\"出演\" + 0.014*\"推出\" + 0.014*\"电视剧\" + 0.013*\"歌曲\" + '\n",
      "  '0.011*\"演唱\" + 0.010*\"演员\" + 0.009*\"台湾\" + 0.009*\"参加\" + 0.009*\"女歌手\" + '\n",
      "  '0.007*\"首张\" + 0.007*\"饰演\" + 0.007*\"年度\" + 0.007*\"香港\"'),\n",
      " (19,\n",
      "  '0.028*\"最佳\" + 0.028*\"专辑\" + 0.016*\"发行\" + 0.012*\"音乐\" + 0.011*\"个人\" + 0.010*\"动作\" '\n",
      "  '+ 0.009*\"电视剧\" + 0.009*\"担任\" + 0.009*\"歌手\" + 0.009*\"提名\" + 0.009*\"台湾\" + '\n",
      "  '0.009*\"冠军\" + 0.009*\"推出\" + 0.008*\"同年\" + 0.007*\"执导\" + 0.007*\"参演\" + 0.007*\"古装\" '\n",
      "  '+ 0.007*\"饰演\" + 0.007*\"演员\" + 0.006*\"首张\"'),\n",
      " (0,\n",
      "  '0.020*\"出演\" + 0.016*\"同年\" + 0.014*\"电视剧\" + 0.013*\"个人\" + 0.011*\"最佳\" + '\n",
      "  '0.011*\"参加\" + 0.010*\"饰演\" + 0.010*\"内地\" + 0.009*\"参演\" + 0.009*\"影视\" + 0.009*\"毕业\" '\n",
      "  '+ 0.009*\"演员\" + 0.008*\"男演员\" + 0.007*\"节目\" + 0.007*\"正式\" + 0.007*\"专辑\" + '\n",
      "  '0.006*\"担任\" + 0.006*\"情感\" + 0.006*\"首部\" + 0.006*\"年度\"')]\n",
      "/home/featurize/data/topics/dangdai/\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/featurize/data/topics/dangdai/\"\n",
    "df_dangdai = seg_corpus(dangdai, save_path)\n",
    "main(save_path, df_dangdai)\n",
    "# df_dangdai  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ahead-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/python/versions/miniconda3-4.7.12/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 4573\n",
      "Number of documents: 9550\n",
      "[(0,\n",
      "  '0.011*\"皇帝\" + 0.011*\"元年\" + 0.008*\"在位\" + 0.008*\"谥号\" + 0.006*\"即位\" + 0.006*\"皇后\" '\n",
      "  '+ 0.006*\"二年\" + 0.005*\"去世\" + 0.005*\"三年\" + 0.005*\"刺史\" + 0.005*\"将军\" + '\n",
      "  '0.004*\"公主\" + 0.004*\"庙号\" + 0.004*\"东汉\" + 0.004*\"概述\" + 0.004*\"来源\" + 0.004*\"次年\" '\n",
      "  '+ 0.004*\"时期\" + 0.003*\"太子\" + 0.003*\"生于\"'),\n",
      " (1,\n",
      "  '0.009*\"公主\" + 0.007*\"司马\" + 0.007*\"将军\" + 0.007*\"时期\" + 0.007*\"去世\" + 0.006*\"皇后\" '\n",
      "  '+ 0.006*\"二年\" + 0.005*\"曹操\" + 0.005*\"册封\" + 0.005*\"元年\" + 0.005*\"谥号\" + '\n",
      "  '0.005*\"蜀汉\" + 0.004*\"即位\" + 0.004*\"大臣\" + 0.004*\"唐朝\" + 0.004*\"成为\" + 0.004*\"贞观\" '\n",
      "  '+ 0.004*\"大将军\" + 0.004*\"刺史\" + 0.003*\"儿子\"'),\n",
      " (2,\n",
      "  '0.010*\"中国\" + 0.009*\"公元前\" + 0.006*\"皇帝\" + 0.005*\"时期\" + 0.004*\"司马懿\" + '\n",
      "  '0.004*\"人物\" + 0.004*\"去世\" + 0.004*\"曹操\" + 0.004*\"将军\" + 0.004*\"谥号\" + 0.004*\"即位\" '\n",
      "  '+ 0.004*\"皇后\" + 0.004*\"元年\" + 0.003*\"公主\" + 0.003*\"在位\" + 0.003*\"生于\" + '\n",
      "  '0.003*\"太子\" + 0.003*\"弟子\" + 0.003*\"部落\" + 0.003*\"成为\"'),\n",
      " (3,\n",
      "  '0.010*\"皇帝\" + 0.008*\"公主\" + 0.008*\"元年\" + 0.007*\"谥号\" + 0.007*\"在位\" + 0.005*\"去世\" '\n",
      "  '+ 0.005*\"唐朝\" + 0.005*\"大将军\" + 0.005*\"司马\" + 0.005*\"北周\" + 0.005*\"刺史\" + '\n",
      "  '0.005*\"建立\" + 0.004*\"中国\" + 0.004*\"时期\" + 0.004*\"大臣\" + 0.004*\"太子\" + 0.004*\"二年\" '\n",
      "  '+ 0.004*\"都督\" + 0.004*\"庙号\" + 0.004*\"不详\"'),\n",
      " (4,\n",
      "  '0.008*\"皇后\" + 0.008*\"谥号\" + 0.008*\"即位\" + 0.008*\"皇帝\" + 0.006*\"元年\" + 0.006*\"康熙\" '\n",
      "  '+ 0.005*\"去世\" + 0.005*\"在位\" + 0.005*\"太子\" + 0.005*\"二年\" + 0.005*\"三年\" + '\n",
      "  '0.004*\"大臣\" + 0.004*\"时期\" + 0.004*\"尚书\" + 0.004*\"将军\" + 0.004*\"河南\" + 0.004*\"乾隆\" '\n",
      "  '+ 0.004*\"四年\" + 0.003*\"公主\" + 0.003*\"刺史\"'),\n",
      " (5,\n",
      "  '0.008*\"公元前\" + 0.007*\"元年\" + 0.007*\"公主\" + 0.006*\"时期\" + 0.006*\"皇后\" + '\n",
      "  '0.006*\"即位\" + 0.005*\"皇帝\" + 0.005*\"去世\" + 0.005*\"唐朝\" + 0.005*\"谥号\" + 0.005*\"二年\" '\n",
      "  '+ 0.004*\"大将军\" + 0.004*\"刺史\" + 0.004*\"成为\" + 0.004*\"之子\" + 0.004*\"东汉\" + '\n",
      "  '0.004*\"建立\" + 0.004*\"宗室\" + 0.004*\"武则天\" + 0.004*\"太子\"'),\n",
      " (6,\n",
      "  '0.009*\"元年\" + 0.007*\"皇后\" + 0.007*\"刺史\" + 0.006*\"将军\" + 0.005*\"太守\" + 0.005*\"尚书\" '\n",
      "  '+ 0.005*\"谥号\" + 0.005*\"即位\" + 0.005*\"时期\" + 0.005*\"二年\" + 0.004*\"大臣\" + '\n",
      "  '0.004*\"去世\" + 0.004*\"孙策\" + 0.004*\"公主\" + 0.004*\"三年\" + 0.004*\"皇帝\" + 0.004*\"雍正\" '\n",
      "  '+ 0.004*\"孙权\" + 0.004*\"平定\" + 0.004*\"北魏\"'),\n",
      " (7,\n",
      "  '0.007*\"中国\" + 0.007*\"出演\" + 0.006*\"时期\" + 0.006*\"将军\" + 0.005*\"去世\" + 0.005*\"主演\" '\n",
      "  '+ 0.005*\"公元前\" + 0.005*\"河南\" + 0.005*\"曹操\" + 0.005*\"生于\" + 0.004*\"成为\" + '\n",
      "  '0.004*\"公主\" + 0.004*\"建立\" + 0.004*\"电影\" + 0.004*\"之子\" + 0.004*\"大臣\" + 0.003*\"太子\" '\n",
      "  '+ 0.003*\"即位\" + 0.003*\"电视剧\" + 0.003*\"太守\"'),\n",
      " (8,\n",
      "  '0.010*\"元年\" + 0.008*\"将军\" + 0.007*\"公主\" + 0.007*\"谥号\" + 0.007*\"二年\" + 0.007*\"即位\" '\n",
      "  '+ 0.007*\"刺史\" + 0.006*\"大臣\" + 0.006*\"去世\" + 0.006*\"皇后\" + 0.005*\"中国\" + '\n",
      "  '0.005*\"出演\" + 0.005*\"郡王\" + 0.005*\"母为\" + 0.005*\"时年\" + 0.004*\"皇帝\" + 0.004*\"三年\" '\n",
      "  '+ 0.004*\"宗室\" + 0.004*\"参演\" + 0.004*\"主演\"'),\n",
      " (9,\n",
      "  '0.010*\"皇后\" + 0.009*\"谥号\" + 0.007*\"皇帝\" + 0.007*\"刺史\" + 0.007*\"即位\" + 0.006*\"去世\" '\n",
      "  '+ 0.006*\"元年\" + 0.006*\"东汉\" + 0.006*\"尚书\" + 0.005*\"历任\" + 0.005*\"大臣\" + '\n",
      "  '0.004*\"将军\" + 0.004*\"时期\" + 0.004*\"太子\" + 0.004*\"河南\" + 0.004*\"三年\" + 0.004*\"司马\" '\n",
      "  '+ 0.004*\"二年\" + 0.004*\"大将军\" + 0.004*\"侍郎\"'),\n",
      " (10,\n",
      "  '0.009*\"执导\" + 0.008*\"中国\" + 0.007*\"导演\" + 0.006*\"监制\" + 0.005*\"演员\" + 0.005*\"获得\" '\n",
      "  '+ 0.005*\"电影\" + 0.005*\"皇后\" + 0.004*\"司马师\" + 0.004*\"黄药师\" + 0.004*\"人物\" + '\n",
      "  '0.004*\"公主\" + 0.004*\"最佳\" + 0.004*\"动作\" + 0.004*\"金庸\" + 0.004*\"香港\" + 0.004*\"元年\" '\n",
      "  '+ 0.003*\"二年\" + 0.003*\"去世\" + 0.003*\"武功\"'),\n",
      " (11,\n",
      "  '0.014*\"中国\" + 0.010*\"发行\" + 0.008*\"专辑\" + 0.008*\"组合\" + 0.007*\"成为\" + 0.007*\"获得\" '\n",
      "  '+ 0.005*\"内地\" + 0.005*\"饰演\" + 0.005*\"担任\" + 0.005*\"出演\" + 0.005*\"同年\" + '\n",
      "  '0.005*\"参演\" + 0.005*\"电视剧\" + 0.004*\"电影\" + 0.004*\"生于\" + 0.004*\"音乐\" + '\n",
      "  '0.004*\"主演\" + 0.004*\"首张\" + 0.003*\"李白\" + 0.003*\"之子\"'),\n",
      " (12,\n",
      "  '0.010*\"皇帝\" + 0.008*\"元年\" + 0.007*\"皇后\" + 0.006*\"去世\" + 0.006*\"时期\" + 0.006*\"刘备\" '\n",
      "  '+ 0.006*\"在位\" + 0.005*\"谥号\" + 0.005*\"曹操\" + 0.005*\"中国\" + 0.004*\"荆州\" + '\n",
      "  '0.004*\"二年\" + 0.004*\"诸葛亮\" + 0.004*\"即位\" + 0.004*\"三年\" + 0.004*\"四年\" + '\n",
      "  '0.004*\"太子\" + 0.004*\"公主\" + 0.004*\"司马\" + 0.003*\"关羽\"'),\n",
      " (13,\n",
      "  '0.018*\"主演\" + 0.017*\"饰演\" + 0.015*\"电视剧\" + 0.012*\"出演\" + 0.011*\"电影\" + '\n",
      "  '0.010*\"参演\" + 0.009*\"中国\" + 0.006*\"同年\" + 0.006*\"刺史\" + 0.006*\"获得\" + 0.006*\"生于\" '\n",
      "  '+ 0.005*\"毕业\" + 0.005*\"演员\" + 0.005*\"大将军\" + 0.005*\"古装\" + 0.004*\"元年\" + '\n",
      "  '0.004*\"内地\" + 0.004*\"都市\" + 0.004*\"执导\" + 0.004*\"播出\"'),\n",
      " (14,\n",
      "  '0.010*\"皇帝\" + 0.010*\"皇后\" + 0.008*\"在位\" + 0.008*\"元年\" + 0.007*\"二年\" + 0.006*\"谥号\" '\n",
      "  '+ 0.006*\"即位\" + 0.005*\"公元前\" + 0.005*\"去世\" + 0.004*\"公元\" + 0.004*\"公主\" + '\n",
      "  '0.004*\"中国\" + 0.004*\"将军\" + 0.003*\"时期\" + 0.003*\"庙号\" + 0.003*\"葬于\" + 0.003*\"母为\" '\n",
      "  '+ 0.003*\"丞相\" + 0.003*\"大将军\" + 0.003*\"刘邦\"'),\n",
      " (15,\n",
      "  '0.011*\"公元前\" + 0.009*\"在位\" + 0.008*\"皇后\" + 0.008*\"皇帝\" + 0.007*\"谥号\" + '\n",
      "  '0.007*\"元年\" + 0.007*\"去世\" + 0.007*\"刺史\" + 0.007*\"即位\" + 0.006*\"中国\" + 0.006*\"将军\" '\n",
      "  '+ 0.005*\"之子\" + 0.004*\"电影\" + 0.004*\"时期\" + 0.004*\"二年\" + 0.004*\"太守\" + '\n",
      "  '0.004*\"太子\" + 0.004*\"成为\" + 0.003*\"三年\" + 0.003*\"七年\"')]\n",
      "/home/featurize/data/topics/gudai/\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/featurize/data/topics/gudai/\"\n",
    "df_gudai = seg_corpus(gudai, save_path)\n",
    "main(save_path, df_gudai)\n",
    "# df_gudai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
